{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model (Play-Level Data) v2\n",
    "\n",
    "__Date:__ 11/5/2023 <br>\n",
    "__Purpose:__ Program that uses the play-level data to predict expected yards gained <br>\n",
    "__Model and data specifications:__\n",
    "- Data: Plays dataframe and some stuff from games df (no outside supplemental data)\n",
    "- Models: Basic supervised learning \n",
    "<br>__Updates from previous version:__ More efficient design of hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, roc_auc_score, auc, f1_score, accuracy_score, roc_curve, RocCurveDisplay, r2_score\n",
    "import time \n",
    "import sys\n",
    "sys.path.append('../preprocessing')\n",
    "from Preprocessing_v3 import *\n",
    "from DataLoader import load_data\n",
    "\n",
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded games df\n",
      "shape: (136, 9)\n",
      "-----\n",
      "loaded players df\n",
      "shape: (1683, 7)\n",
      "-----\n",
      "loaded plays df\n",
      "shape: (12486, 35)\n",
      "-----\n",
      "loading tracking frames...\n",
      "loaded tracking frames\n",
      "shape: (12187398, 17)\n",
      "returning 4 frames\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "[games_df, players_df, plays_df, tracking_df] = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that finishes preprocessing and does the train test split of plays df\n",
    "def plays_train_test_split(plays_df_clean):\n",
    "    # Drop game and play ID\n",
    "    plays_df_clean = plays_df_clean.drop(['gameId', 'playId'], axis = 1)\n",
    "    \n",
    "    # Get X and y matrices\n",
    "    y = plays_df_clean[\"TARGET\"]\n",
    "    X = plays_df_clean.drop([\"TARGET\"], axis = 1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=24)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that does cross validation and gives best model\n",
    "def run_cv(model, param_grid, X_train, y_train, X_val):\n",
    "    print(\"training \" + str(model))\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cv = KFold(n_splits=5)\n",
    "\n",
    "    # Get the type of scoring for the grid search depending on regression or classification\n",
    "    if model in [LinearRegression, Lasso, Ridge, ElasticNet, SVR, RandomForestRegressor, AdaBoostRegressor, XGBRegressor]:\n",
    "        scoring_metric = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        scoring_metric = 'f1_weighted'\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(estimator=model(), param_grid=param_grid, cv=cv, scoring=scoring_metric)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.predict(X_val)\n",
    "\n",
    "    # Return the best model, y_pred\n",
    "    return grid_search, y_pred, train_time # return the metric and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of models and parameters\n",
    "regression_models = {LinearRegression : {},\n",
    "                     Lasso : {'alpha': [0.001, 0.01, 0.1, 1, 2]},\n",
    "                     Ridge :  {'alpha': [0.001, 0.01, 0.1, 1, 2]},\n",
    "                     ElasticNet : {'alpha': [0.001, 0.01, 0.1, 1, 2], \n",
    "                                   'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9]},\n",
    "                     # SVR : {'C': [0.01, 0.1, 1, 2, 10], 'kernel': ['linear', 'poly', 'rbf']},\n",
    "                     RandomForestRegressor : {'n_estimators': [100, 500, 1000],\n",
    "                                              'max_depth': [100, None]},\n",
    "                     AdaBoostRegressor : {'n_estimators': [50, 100, 200],\n",
    "                                          'learning_rate': [0.001, 0.01, 0.1, 1, 2]},\n",
    "                     XGBRegressor : {'max_depth': [3, 5, 6, 7], \n",
    "                                     'learning_rate': [0.1, 0.3, 0.5], \n",
    "                                     'subsample': [0.5, 0.7, 1]}                    \n",
    "}\n",
    "\n",
    "classification_models = {\n",
    "    # SVR : {'C': [0.01, 0.1, 1, 2, 10], 'kernel': ['linear', 'poly', 'rbf']},\n",
    "    RandomForestClassifier : {'n_estimators': [100, 500, 1000],\n",
    "                            'max_depth': [100, None]},\n",
    "    AdaBoostClassifier : {'n_estimators': [50, 100, 200],\n",
    "                        'learning_rate': [0.001, 0.01, 0.1, 1, 2]},\n",
    "    XGBClassifier : {'max_depth': [3, 5, 6, 7], \n",
    "                    'learning_rate': [0.1, 0.3, 0.5], \n",
    "                    'subsample': [0.5, 0.7, 1]} ,\n",
    "    LogisticRegression : {'penalty': ['l1', 'l2', 'elasticnet', None]},\n",
    "    GaussianNB : {},\n",
    "    Perceptron : {'penalty': ['l1', 'l2', 'elasticnet']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final plays data shape: (6840, 289)\n",
      "training <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "training <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "10 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.14248144        nan 0.14248144]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.naive_bayes.GaussianNB'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._perceptron.Perceptron'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final plays data shape: (6840, 289)\n",
      "training <class 'sklearn.linear_model._base.LinearRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.418e+01, tolerance: 1.892e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._ridge.Ridge'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._coordinate_descent.ElasticNet'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.ensemble._forest.RandomForestRegressor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'xgboost.sklearn.XGBRegressor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final plays data shape: (6840, 289)\n",
      "training <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "10 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.14248144        nan 0.14248144]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.naive_bayes.GaussianNB'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._perceptron.Perceptron'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:74: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final plays data shape: (6840, 289)\n",
      "training <class 'sklearn.linear_model._base.LinearRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._ridge.Ridge'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.linear_model._coordinate_descent.ElasticNet'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.ensemble._forest.RandomForestRegressor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'xgboost.sklearn.XGBRegressor'>\n",
      "total time: 6156.050206899643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/y2pysqbx2wg4rrlhdnq0djrc0000gn/T/ipykernel_65501/3189500133.py:49: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>regression/classification</th>\n",
       "      <th>train_time</th>\n",
       "      <th>MSE pre-bin</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>bin_output</th>\n",
       "      <th>include_nfl_features</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier(max_depth=100)</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.213827</td>\n",
       "      <td>[[3, 6, 7, 3, 51, 19, 1], [0, 20, 12, 16, 112,...</td>\n",
       "      <td>0.269591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier(learning_rate=1, n_estimato...</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.227863</td>\n",
       "      <td>[[6, 8, 1, 3, 61, 7, 4], [6, 16, 7, 12, 117, 2...</td>\n",
       "      <td>0.283041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.218369</td>\n",
       "      <td>[[3, 8, 10, 4, 42, 18, 5], [3, 25, 16, 19, 83,...</td>\n",
       "      <td>0.246784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.183787</td>\n",
       "      <td>[[24, 14, 8, 4, 16, 11, 13], [37, 41, 28, 11, ...</td>\n",
       "      <td>0.179532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "0              RandomForestClassifier(max_depth=100)   \n",
       "1  AdaBoostClassifier(learning_rate=1, n_estimato...   \n",
       "2  XGBClassifier(base_score=None, booster=None, c...   \n",
       "3                               LogisticRegression()   \n",
       "4                                       GaussianNB()   \n",
       "\n",
       "  regression/classification  train_time  MSE pre-bin  r2_score bin_output  \\\n",
       "0            classification    0.000029          NaN       NaN       True   \n",
       "1            classification    0.000041          NaN       NaN       True   \n",
       "2            classification    0.000027          NaN       NaN       True   \n",
       "3            classification    0.000017          NaN       NaN       True   \n",
       "4            classification    0.000009          NaN       NaN       True   \n",
       "\n",
       "  include_nfl_features  f1_score  \\\n",
       "0                 True  0.213827   \n",
       "1                 True  0.227863   \n",
       "2                 True  0.218369   \n",
       "3                 True  0.132776   \n",
       "4                 True  0.183787   \n",
       "\n",
       "                                    confusion_matrix  accuracy_score  \n",
       "0  [[3, 6, 7, 3, 51, 19, 1], [0, 20, 12, 16, 112,...        0.269591  \n",
       "1  [[6, 8, 1, 3, 61, 7, 4], [6, 16, 7, 12, 117, 2...        0.283041  \n",
       "2  [[3, 8, 10, 4, 42, 18, 5], [3, 25, 16, 19, 83,...        0.246784  \n",
       "3  [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "4  [[24, 14, 8, 4, 16, 11, 13], [37, 41, 28, 11, ...        0.179532  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_nfl_features_params = [True, False]\n",
    "bin_ouput_params = [True, False]\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['model', 'regression/classification', 'train_time',\n",
    "                                                'MSE pre-bin', 'r2_score',\n",
    "                                                'bin_output', 'include_nfl_features',\n",
    "                                                'f1_score','confusion_matrix', 'accuracy_score'])\n",
    "start_time = time.time()\n",
    "for include_nfl_features in include_nfl_features_params:\n",
    "    for bin_output in bin_ouput_params: \n",
    "        # Prepreocessing \n",
    "        plays_df_clean = preprocess_plays_df_naive_models(plays_df, games_df, include_nfl_features, bin_output)\n",
    "\n",
    "        # Train test split\n",
    "        X_train, X_test, y_train, y_test = plays_train_test_split(plays_df_clean)\n",
    "\n",
    "        # Check if we need to do regression first\n",
    "        if not bin_output:\n",
    "            for model_class in regression_models.keys():\n",
    "                # Train model\n",
    "                model, y_pred, train_time = run_cv(model_class, regression_models[model_class], X_train, y_train, X_test)\n",
    "\n",
    "                # Get regression accuracy\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                # Bin both and get post-binned metrics\n",
    "                bins = [float('-inf'), -2, 0, 1, 2.5, 5, 10, float('inf')]\n",
    "                y_pred_binned = pd.cut(y_pred, bins = bins, labels = range(len(bins) - 1))\n",
    "                y_test_binned = pd.cut(y_test, bins = bins, labels = range(len(bins) - 1))\n",
    "\n",
    "                f1_metric = f1_score(y_test_binned, y_pred_binned, average = 'weighted')\n",
    "                confusion_mat = confusion_matrix(y_test_binned, y_pred_binned)\n",
    "                accuracy = accuracy_score(y_test_binned, y_pred_binned)\n",
    "\n",
    "                # Record result\n",
    "                new_row = pd.DataFrame({\n",
    "                    'model': [str(model.best_estimator_)],\n",
    "                    'regression/classification': ['regression'], \n",
    "                    'train_time': [train_time],\n",
    "                    'MSE pre-bin': [mse], \n",
    "                    'r2_score': [r2],\n",
    "                    'bin_output': [bin_output], \n",
    "                    'include_nfl_features': [include_nfl_features],\n",
    "                    'f1_score': [f1_metric],\n",
    "                    'confusion_matrix': [confusion_mat], \n",
    "                    'accuracy_score': [accuracy]\n",
    "                })\n",
    "                results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            for model_class in classification_models.keys():\n",
    "                # Train model\n",
    "                model, y_pred, train_time = run_cv(model_class, classification_models[model_class], X_train, y_train, X_test)\n",
    "\n",
    "                # Get accuracy metrics\n",
    "                f1_metric = f1_score(y_test, y_pred, average = 'weighted')\n",
    "                confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Record result\n",
    "                new_row = pd.DataFrame({\n",
    "                    'model': str(model.best_estimator_),\n",
    "                    'regression/classification': ['classification'], \n",
    "                    'train_time': [train_time],\n",
    "                    'MSE pre-bin': [np.nan], \n",
    "                    'r2_score': [np.nan],\n",
    "                    'bin_output': [bin_output], \n",
    "                    'include_nfl_features': [include_nfl_features],\n",
    "                    'f1_score': [f1_metric],\n",
    "                    'confusion_matrix': [confusion_mat], \n",
    "                    'accuracy_score': [accuracy]\n",
    "                })\n",
    "                results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "print(\"total time: \" + str(time.time() - start_time))\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>regression/classification</th>\n",
       "      <th>train_time</th>\n",
       "      <th>MSE pre-bin</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>bin_output</th>\n",
       "      <th>include_nfl_features</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso(alpha=0.01)</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>41.099802</td>\n",
       "      <td>0.035553</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.184253</td>\n",
       "      <td>[[0, 0, 2, 6, 48, 34, 0], [0, 1, 3, 12, 111, 5...</td>\n",
       "      <td>0.262573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ElasticNet(alpha=0.1, l1_ratio=0.1)</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>41.188025</td>\n",
       "      <td>0.033483</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.183696</td>\n",
       "      <td>[[0, 0, 0, 6, 50, 34, 0], [0, 0, 2, 12, 114, 5...</td>\n",
       "      <td>0.265497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lasso(alpha=0.01)</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>41.397970</td>\n",
       "      <td>0.028556</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.173103</td>\n",
       "      <td>[[0, 0, 0, 4, 56, 30, 0], [0, 0, 2, 11, 121, 5...</td>\n",
       "      <td>0.257895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ElasticNet(alpha=0.1, l1_ratio=0.1)</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>41.473352</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176083</td>\n",
       "      <td>[[0, 0, 0, 3, 59, 28, 0], [0, 0, 0, 8, 118, 58...</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, ca...</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>41.909196</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.196191</td>\n",
       "      <td>[[0, 0, 3, 6, 49, 32, 0], [0, 2, 7, 15, 106, 5...</td>\n",
       "      <td>0.264327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  \\\n",
       "7                                   Lasso(alpha=0.01)   \n",
       "9                 ElasticNet(alpha=0.1, l1_ratio=0.1)   \n",
       "20                                  Lasso(alpha=0.01)   \n",
       "22                ElasticNet(alpha=0.1, l1_ratio=0.1)   \n",
       "12  XGBRegressor(base_score=None, booster=None, ca...   \n",
       "\n",
       "   regression/classification  train_time  MSE pre-bin  r2_score bin_output  \\\n",
       "7             classification    0.000018    41.099802  0.035553      False   \n",
       "9             classification    0.000016    41.188025  0.033483      False   \n",
       "20            classification    0.000018    41.397970  0.028556      False   \n",
       "22            classification    0.000016    41.473352  0.026788      False   \n",
       "12            classification    0.000064    41.909196  0.016560      False   \n",
       "\n",
       "   include_nfl_features  f1_score  \\\n",
       "7                  True  0.184253   \n",
       "9                  True  0.183696   \n",
       "20                False  0.173103   \n",
       "22                False  0.176083   \n",
       "12                 True  0.196191   \n",
       "\n",
       "                                     confusion_matrix  accuracy_score  \n",
       "7   [[0, 0, 2, 6, 48, 34, 0], [0, 1, 3, 12, 111, 5...        0.262573  \n",
       "9   [[0, 0, 0, 6, 50, 34, 0], [0, 0, 2, 12, 114, 5...        0.265497  \n",
       "20  [[0, 0, 0, 4, 56, 30, 0], [0, 0, 2, 11, 121, 5...        0.257895  \n",
       "22  [[0, 0, 0, 3, 59, 28, 0], [0, 0, 0, 8, 118, 58...        0.263158  \n",
       "12  [[0, 0, 3, 6, 49, 32, 0], [0, 2, 7, 15, 106, 5...        0.264327  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = 'MSE pre-bin').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaBoostClassifier(learning_rate=1, n_estimators=200)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = 'f1_score', ascending = False).iloc[0]['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depreciated - run through on one dataset/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get X and y matrices\n",
    "# y = plays_df_clean[\"TARGET\"]\n",
    "# X = plays_df_clean.drop([\"TARGET\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=24)\n",
    "\n",
    "# print('X_train shape : ', X_train.shape)\n",
    "# print('y_train shape : ', y_train.shape)\n",
    "\n",
    "# print('X_test shape  : ', X_test.shape)\n",
    "# print('y_test shape  : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# model.__class__\n",
    "\n",
    "# # Get the type of scoring for the grid search depending on regression or classification\n",
    "# if model.__class__ in [LinearRegression, Lasso, Ridge, ElasticNet, SVR, RandomForestRegressor, AdaBoostRegressor, XGBRegressor]:\n",
    "#     scoring_metric = 'neg_mean_squared_error'\n",
    "# else:\n",
    "#     scoring_metric = 'f1_weighted'\n",
    "\n",
    "# print(scoring_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train model\n",
    "\n",
    "    \n",
    "\n",
    "# grid_search = GridSearchCV(estimator=LinearRegression(), param_grid={}, cv=KFold(5), scoring='neg_mean_squared_error')\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# y_pred = grid_search.predict(X_test)\n",
    "\n",
    "\n",
    "# # Get accuracy\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# # Bin both and get post-binned metrics\n",
    "# bins = [float('-inf'), -2, 0, 1, 2.5, 5, 10, float('inf')]\n",
    "# y_pred_binned = pd.cut(y_pred, bins = bins, labels = range(len(bins) - 1))\n",
    "# y_test_binned = pd.cut(y_test, bins = bins, labels = range(len(bins) - 1))\n",
    "\n",
    "# f1_metric = f1_score(y_test_binned, y_pred_binned, average = 'weighted')\n",
    "# confusion_mat = confusion_matrix(y_test_binned, y_pred_binned)\n",
    "# accuracy = accuracy_score(y_test_binned, y_pred_binned)\n",
    "\n",
    "# # Record result\n",
    "# new_row = pd.DataFrame({\n",
    "#     'model': [str(model.best_estimator_)],\n",
    "#     'regression/classification': ['classification'], \n",
    "#     'train_time': [train_time],\n",
    "#     'MSE pre-bin': [mse], \n",
    "#     'r2_score': [r2],\n",
    "#     'bin_output': [bin_output], \n",
    "#     'include_nfl_features': [include_nfl_features],\n",
    "#     'f1_score': [f1_metric],\n",
    "#     'confusion_matrix': [confusion_mat], \n",
    "#     'accuracy_score': [accuracy]\n",
    "# })\n",
    "# print(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepreocessing \n",
    "# plays_df_clean = preprocess_plays_df_naive_models(plays_df, games_df, True, False)\n",
    "\n",
    "# # Train test split\n",
    "# X_train, X_test, y_train, y_test = plays_train_test_split(plays_df_clean)\n",
    "\n",
    "# start_time = time.time()\n",
    "# model = XGBRegressor(learning_rate=1, n_estimators=200)\n",
    "# model.fit(X = X_train, y = y_train)\n",
    "# print(\"training time: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Confusion matrix: \\n\" + str(confusion_matrix(y_test, y_pred)))\n",
    "# print(\"F1 score: \" + str(round(f1_score(y_test, y_pred, average='weighted'), 3)))\n",
    "# print(\"Accuracy score: \" + str(round(accuracy_score(y_test, y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"MSE: \\n\" + str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = [float('-inf'), -2, 0, 1, 2.5, 5, 10, float('inf')]\n",
    "# y_pred_binned = pd.cut(y_pred, bins = bins, labels = range(len(bins) - 1))\n",
    "# y_test_binned = pd.cut(y_test, bins = bins, labels = range(len(bins) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Confusion matrix: \\n\" + str(confusion_matrix(y_test_binned, y_pred_binned)))\n",
    "# print(\"F1 score: \" + str(round(f1_score(y_test_binned, y_pred_binned, average='weighted'), 3)))\n",
    "# print(\"Accuracy score: \" + str(round(accuracy_score(y_test_binned, y_pred_binned), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

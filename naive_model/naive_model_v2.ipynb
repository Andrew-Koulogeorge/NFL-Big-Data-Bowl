{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model (Play-Level Data) v2\n",
    "\n",
    "__Date:__ 11/5/2023 <br>\n",
    "__Purpose:__ Program that uses the play-level data to predict expected yards gained <br>\n",
    "__Model and data specifications:__\n",
    "- Data: Plays dataframe and some stuff from games df (no outside supplemental data)\n",
    "- Models: Basic supervised learning \n",
    "<br>__Updates from previous version:__ More efficient design of hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, roc_auc_score, auc, f1_score, accuracy_score, roc_curve, RocCurveDisplay, r2_score\n",
    "import time \n",
    "import sys\n",
    "sys.path.append('../preprocessing')\n",
    "from Preprocessing_v1 import *\n",
    "from DataLoader import load_data\n",
    "\n",
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "[games_df, players_df, plays_df, tracking_df] = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that finishes preprocessing and does the train test split of plays df\n",
    "def plays_train_test_split(plays_df_clean):\n",
    "    # Drop game and play ID\n",
    "    plays_df_clean = plays_df_clean.drop(['gameId', 'playId'], axis = 1)\n",
    "    \n",
    "    # Get X and y matrices\n",
    "    y = plays_df_clean[\"TARGET\"]\n",
    "    X = plays_df_clean.drop([\"TARGET\"], axis = 1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=24)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that does cross validation and gives best model\n",
    "def run_cv(model, param_grid, X_train, y_train, X_val):\n",
    "    print(\"training \" + type(model).__name__)\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cv = KFold(n_splits=5)\n",
    "\n",
    "    # Get the type of scoring for the grid search depending on regression or classification\n",
    "    if model in [LinearRegression, Lasso, Ridge, ElasticNet, SVR, RandomForestRegressor, AdaBoostRegressor, XGBRegressor]:\n",
    "        scoring_metric = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        scoring_metric = 'f1_weighted'\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(estimator=model(), param_grid=param_grid, cv=cv, scoring=scoring_metric)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.predict(X_val)\n",
    "\n",
    "    # Return the best model, y_pred\n",
    "    return grid_search, y_pred, train_time # return the metric and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of models and parameters\n",
    "regression_models = {LinearRegression : {},\n",
    "                     Lasso : {'alpha': [0.001, 0.01, 0.1, 1, 2]},\n",
    "                     Ridge :  {'alpha': [0.001, 0.01, 0.1, 1, 2]},\n",
    "                     ElasticNet : {'alpha': [0.001, 0.01, 0.1, 1, 2], \n",
    "                                   'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9]},\n",
    "                     # SVR : {'C': [0.01, 0.1, 1, 2, 10], 'kernel': ['linear', 'poly', 'rbf']},\n",
    "                     RandomForestRegressor : {'n_estimators': [100, 500, 1000],\n",
    "                                              'max_depth': [100, None]},\n",
    "                     AdaBoostRegressor : {'n_estimators': [50, 100, 200],\n",
    "                                          'learning_rate': [0.001, 0.01, 0.1, 1, 2]},\n",
    "                     XGBRegressor : {'max_depth': [3, 5, 6, 7], \n",
    "                                     'learning_rate': [0.1, 0.3, 0.5], \n",
    "                                     'subsample': [0.5, 0.7, 1]}                    \n",
    "}\n",
    "\n",
    "classification_models = {\n",
    "    # SVR : {'C': [0.01, 0.1, 1, 2, 10], 'kernel': ['linear', 'poly', 'rbf']},\n",
    "    RandomForestClassifier : {'n_estimators': [100, 500, 1000],\n",
    "                            'max_depth': [100, None]},\n",
    "    AdaBoostClassifier : {'n_estimators': [50, 100, 200],\n",
    "                        'learning_rate': [0.001, 0.01, 0.1, 1, 2]},\n",
    "    XGBClassifier : {'max_depth': [3, 5, 6, 7], \n",
    "                    'learning_rate': [0.1, 0.3, 0.5], \n",
    "                    'subsample': [0.5, 0.7, 1]} ,\n",
    "    LogisticRegression : {'penalty': ['l1', 'l2', 'elasticnet', None]},\n",
    "    GaussianNB : {},\n",
    "    Perceptron : {'penalty': ['l1', 'l2', 'elasticnet']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_nfl_features_params = [True, False]\n",
    "bin_ouput_params = [True, False]\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['model', 'regression/classification', 'train_time',\n",
    "                                                'MSE pre-bin', 'r2_score',\n",
    "                                                'bin_output', 'include_nfl_features',\n",
    "                                                'f1_score','confusion_matrix', 'accuracy_score'])\n",
    "\n",
    "for include_nfl_features in include_nfl_features_params:\n",
    "    for bin_output in bin_ouput_params: \n",
    "        # Prepreocessing \n",
    "        plays_df_clean = preprocess_plays_df_naive_models(plays_df, games_df, include_nfl_features, bin_output)\n",
    "\n",
    "        # Train test split\n",
    "        X_train, X_test, y_train, y_test = plays_train_test_split(plays_df_clean)\n",
    "\n",
    "        # Check if we need to do regression first\n",
    "        if not bin_output:\n",
    "            for model_class in regression_models.keys():\n",
    "                # Train model\n",
    "                model, y_pred, train_time = run_cv(model_class, regression_models[model_class], X_train, y_train, X_test)\n",
    "\n",
    "                # Get regression accuracy\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                # Bin both and get post-binned metrics\n",
    "                bins = [float('-inf'), -2, 0, 1, 2.5, 5, 10, float('inf')]\n",
    "                y_pred_binned = pd.cut(y_pred, bins = bins, labels = range(len(bins) - 1))\n",
    "                y_test_binned = pd.cut(y_test, bins = bins, labels = range(len(bins) - 1))\n",
    "\n",
    "                f1_metric = f1_score(y_test_binned, y_pred_binned, average = 'weighted')\n",
    "                confusion_mat = confusion_matrix(y_test_binned, y_pred_binned)\n",
    "                accuracy = accuracy_score(y_test_binned, y_pred_binned)\n",
    "\n",
    "                # Record result\n",
    "                new_row = pd.DataFrame({\n",
    "                    'model': [str(model.best_estimator_)],\n",
    "                    'regression/classification': ['classification'], \n",
    "                    'train_time': [train_time],\n",
    "                    'MSE pre-bin': [mse], \n",
    "                    'r2_score': [r2],\n",
    "                    'bin_output': [bin_output], \n",
    "                    'include_nfl_features': [include_nfl_features],\n",
    "                    'f1_score': [f1_metric],\n",
    "                    'confusion_matrix': [confusion_mat], \n",
    "                    'accuracy_score': [accuracy]\n",
    "                })\n",
    "                results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            for model_class in classification_models.keys():\n",
    "                # Train model\n",
    "                model, y_pred, train_time = run_cv(model_class, classification_models[model_class], X_train, y_train, X_test)\n",
    "\n",
    "                # Get accuracy metrics\n",
    "                f1_metric = f1_score(y_test, y_pred, average = 'weighted')\n",
    "                confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Record result\n",
    "                new_row = pd.DataFrame({\n",
    "                    'model': str(model.best_estimator_),\n",
    "                    'regression/classification': ['classification'], \n",
    "                    'train_time': [train_time],\n",
    "                    'MSE pre-bin': [np.nan], \n",
    "                    'r2_score': [np.nan],\n",
    "                    'bin_output': [bin_output], \n",
    "                    'include_nfl_features': [include_nfl_features],\n",
    "                    'f1_score': [f1_metric],\n",
    "                    'confusion_matrix': [confusion_mat], \n",
    "                    'accuracy_score': [accuracy]\n",
    "                })\n",
    "                results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by = 'f1_score', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by = 'f1_score', ascending = False).iloc[0]['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depreciated - run through on one dataset/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y matrices\n",
    "y = plays_df_clean[\"TARGET\"]\n",
    "X = plays_df_clean.drop([\"TARGET\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=24)\n",
    "\n",
    "print('X_train shape : ', X_train.shape)\n",
    "print('y_train shape : ', y_train.shape)\n",
    "\n",
    "print('X_test shape  : ', X_test.shape)\n",
    "print('y_test shape  : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.__class__\n",
    "\n",
    "# Get the type of scoring for the grid search depending on regression or classification\n",
    "if model.__class__ in [LinearRegression, Lasso, Ridge, ElasticNet, SVR, RandomForestRegressor, AdaBoostRegressor, XGBRegressor]:\n",
    "    scoring_metric = 'neg_mean_squared_error'\n",
    "else:\n",
    "    scoring_metric = 'f1_weighted'\n",
    "\n",
    "print(scoring_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "    \n",
    "\n",
    "grid_search = GridSearchCV(estimator=LinearRegression(), param_grid={}, cv=KFold(5), scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "\n",
    "# Get accuracy\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Bin both and get post-binned metrics\n",
    "bins = [float('-inf'), -2, 0, 1, 2.5, 5, 10, float('inf')]\n",
    "y_pred_binned = pd.cut(y_pred, bins = bins, labels = range(len(bins) - 1))\n",
    "y_test_binned = pd.cut(y_test, bins = bins, labels = range(len(bins) - 1))\n",
    "\n",
    "f1_metric = f1_score(y_test_binned, y_pred_binned, average = 'weighted')\n",
    "confusion_mat = confusion_matrix(y_test_binned, y_pred_binned)\n",
    "accuracy = accuracy_score(y_test_binned, y_pred_binned)\n",
    "\n",
    "# Record result\n",
    "new_row = pd.DataFrame({\n",
    "    'model': [str(model.best_estimator_)],\n",
    "    'regression/classification': ['classification'], \n",
    "    'train_time': [train_time],\n",
    "    'MSE pre-bin': [mse], \n",
    "    'r2_score': [r2],\n",
    "    'bin_output': [bin_output], \n",
    "    'include_nfl_features': [include_nfl_features],\n",
    "    'f1_score': [f1_metric],\n",
    "    'confusion_matrix': [confusion_mat], \n",
    "    'accuracy_score': [accuracy]\n",
    "})\n",
    "print(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepreocessing \n",
    "plays_df_clean = preprocess_plays_df_naive_models(plays_df, games_df, True, False)\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = plays_train_test_split(plays_df_clean)\n",
    "\n",
    "start_time = time.time()\n",
    "model = XGBRegressor(learning_rate=1, n_estimators=200)\n",
    "model.fit(X = X_train, y = y_train)\n",
    "print(\"training time: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix: \\n\" + str(confusion_matrix(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(round(f1_score(y_test, y_pred, average='weighted'), 3)))\n",
    "print(\"Accuracy score: \" + str(round(accuracy_score(y_test, y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE: \\n\" + str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [float('-inf'), -2, 0, 1, 2.5, 5, 10, float('inf')]\n",
    "y_pred_binned = pd.cut(y_pred, bins = bins, labels = range(len(bins) - 1))\n",
    "y_test_binned = pd.cut(y_test, bins = bins, labels = range(len(bins) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix: \\n\" + str(confusion_matrix(y_test_binned, y_pred_binned)))\n",
    "print(\"F1 score: \" + str(round(f1_score(y_test_binned, y_pred_binned, average='weighted'), 3)))\n",
    "print(\"Accuracy score: \" + str(round(accuracy_score(y_test_binned, y_pred_binned), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

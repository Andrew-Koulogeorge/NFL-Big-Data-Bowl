{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model (Play-Level Data) v1\n",
    "\n",
    "__Date:__ 11/5/2023 <br>\n",
    "__Purpose:__ Program that uses the play-level data to predict expected yards gained <br>\n",
    "__Model and data specifications:__\n",
    "- Data: Plays dataframe and some stuff from games df (no outside supplemental data)\n",
    "- Models: Basic supervised learning \n",
    "<br>__Updates from previous version:__ Includes hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, roc_auc_score, auc, f1_score, accuracy_score, roc_curve, RocCurveDisplay, r2_score\n",
    "import time \n",
    "import sys\n",
    "sys.path.append('../preprocessing')\n",
    "from Preprocessing_v1 import *\n",
    "from DataLoader import load_data\n",
    "\n",
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded games df\n",
      "shape: (136, 9)\n",
      "-----\n",
      "loaded players df\n",
      "shape: (1683, 7)\n",
      "-----\n",
      "loaded plays df\n",
      "shape: (12486, 35)\n",
      "-----\n",
      "loading tracking frames...\n",
      "loaded tracking frames\n",
      "shape: (12187398, 17)\n",
      "returning 4 frames\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "[games_df, players_df, plays_df, tracking_df] = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that finishes preprocessing and does the train test split of plays df\n",
    "def plays_train_test_split(plays_df_clean):\n",
    "    # Drop game and play ID\n",
    "    plays_df_clean = plays_df_clean.drop(['gameId', 'playId'], axis = 1)\n",
    "    \n",
    "    # Get X and y matrices\n",
    "    y = plays_df_clean[\"TARGET\"]\n",
    "    X = plays_df_clean.drop([\"TARGET\"], axis = 1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=24)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that does cross validation and gives best model\n",
    "def run_cv(model, param_grid, X_train, y_train, X_val):\n",
    "    print(\"training \" + type(model).__name__)\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cv = KFold(n_splits=5)\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='f1_weighted')\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.predict(X_val)\n",
    "\n",
    "    # Return the best model, y_pred\n",
    "    return grid_search, y_pred, train_time # return the metric and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper fucntions that do cross validation\n",
    "\n",
    "def run_lasso(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 2]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(Lasso(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_ridge(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 2]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(Ridge(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_elastic_net(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 2],\n",
    "                  'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(ElasticNet(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_SVR(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'C': [0.01, 0.1, 1, 2, 10],\n",
    "                  'kernel': ['linear', 'poly', 'rbf']}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(SVR(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_random_forest_reg(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'n_estimators': [100, 500, 1000],\n",
    "                  'max_depth': [100, None]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(RandomForestRegressor(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_adaboost_reg(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'n_estimators': [50, 100, 200],\n",
    "                  'learning_rate': [0.001, 0.01, 0.1, 1, 2]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(AdaBoostRegressor(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_xgb_reg(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'max_depth': [3, 5, 6, 7],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'subsample': [0.5, 0.7, 1]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(XGBRegressor(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_xgb_classifier(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'max_depth': [3, 5, 6, 7],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'subsample': [0.5, 0.7, 1]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(XGBClassifier(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_logistic_classifier(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid for regularization strength\n",
    "    param_grid = {'penalty': ['l1', 'l2', 'elasticnet', None]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(LogisticRegression(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_SVC(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'C': [0.01, 0.1, 1, 2, 10],\n",
    "                  'kernel': ['linear', 'poly', 'rbf']}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(SVC(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_random_forest_classifier(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'n_estimators': [100, 500, 1000],\n",
    "                  'max_depth': [100, None]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(RandomForestClassifier(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_adaboost_classifier(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'n_estimators': [50, 100, 200],\n",
    "                  'learning_rate': [0.001, 0.01, 0.1, 1, 2]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(AdaBoostClassifier(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "\n",
    "def run_gaussianNB(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 2]}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(GaussianNB(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "def run_perceptron(X_train, y_train, X_test):\n",
    "    # Define the hyperparameter grid \n",
    "    param_grid = {'penalty': ['l1', 'l2', 'elasticnet']}\n",
    "\n",
    "    # Get the best model and predictions\n",
    "    grid_search, y_pred, train_time = run_cv(Perceptron(), param_grid, X_train, y_train, X_test)\n",
    "    return grid_search, y_pred, train_time\n",
    "\n",
    "# Linear regression (no tuning necessary)\n",
    "def run_linear_reg(X_train, y_train, X_test):\n",
    "    # Train model\n",
    "    model = LinearRegression()\n",
    "    print(\"training \" + type(model).__name__)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return model, y_pred, train_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final plays data shape: (6840, 289)\n",
      "training LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "10 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.14248144        nan 0.14248144]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Perceptron\n"
     ]
    }
   ],
   "source": [
    "include_nfl_features_params = [True, False]\n",
    "bin_ouput_params = [True, False]\n",
    "\n",
    "results_df = pd.DataFrame(columns = ['model', 'regression/classification', 'train_time',\n",
    "                                                'MSE pre-bin', 'r2_score',\n",
    "                                                'bin_output', 'include_nfl_features',\n",
    "                                                'f1_score','confusion_matrix', 'accuracy_score'])\n",
    "\n",
    "regression_models = [run_linear_reg, run_lasso, run_ridge, run_elastic_net, run_SVR, run_random_forest_reg, run_adaboost_reg, run_xgb_reg]\n",
    "classification_models = [run_logistic_classifier, run_perceptron, run_gaussianNB, run_SVC, run_random_forest_classifier, run_adaboost_classifier, run_xgb_classifier]\n",
    "\n",
    "for include_nfl_features in include_nfl_features_params:\n",
    "    for bin_output in bin_ouput_params: \n",
    "        # Prepreocessing \n",
    "        plays_df_clean = preprocess_plays_df_naive_models(plays_df, games_df, include_nfl_features, bin_output)\n",
    "\n",
    "        # Train test split\n",
    "        X_train, X_test, y_train, y_test = plays_train_test_split(plays_df_clean)\n",
    "\n",
    "        # Check if we need to do regression first\n",
    "        if not bin_output:\n",
    "            for model_class in regression_models:\n",
    "                # Train model\n",
    "                model, y_pred, train_time = model_class(X_train, y_train, X_test)\n",
    "\n",
    "                # Get accuracy\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                # Bin both and get post-binned metrics\n",
    "                bins = [float('-inf'), -2, 0, 1, 2.5, 5, 10, float('inf')]\n",
    "                y_pred_binned = pd.cut(y_pred, bins = bins, labels = range(len(bins) - 1))\n",
    "                y_test_binned = pd.cut(y_test, bins = bins, labels = range(len(bins) - 1))\n",
    "\n",
    "                f1_metric = f1_score(y_test_binned, y_pred_binned, average = 'weighted')\n",
    "                confusion_mat = confusion_matrix(y_test_binned, y_pred_binned)\n",
    "                accuracy = accuracy_score(y_test_binned, y_pred_binned)\n",
    "\n",
    "                # Record result\n",
    "                new_row = pd.DataFrame({\n",
    "                    'model': [type(model).__name__],\n",
    "                    'regression/classification': ['classification'], \n",
    "                    'train_time': [train_time],\n",
    "                    'MSE pre-bin': [mse], \n",
    "                    'r2_score': [r2],\n",
    "                    'bin_output': [bin_output], \n",
    "                    'include_nfl_features': [include_nfl_features],\n",
    "                    'f1_score': [f1_metric],\n",
    "                    'confusion_matrix': [confusion_mat], \n",
    "                    'accuracy_score': [accuracy]\n",
    "                })\n",
    "                results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            for model_class in classification_models:\n",
    "                # Train model\n",
    "                model, y_pred, train_time = model_class(X_train, y_train, X_test)\n",
    "\n",
    "                # Get accuracy metrics\n",
    "                f1_metric = f1_score(y_test, y_pred, average = 'weighted')\n",
    "                confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Record result\n",
    "                new_row = pd.DataFrame({\n",
    "                    'model': [type(model).__name__],\n",
    "                    'regression/classification': ['classification'], \n",
    "                    'train_time': [train_time],\n",
    "                    'MSE pre-bin': [np.nan], \n",
    "                    'r2_score': [np.nan],\n",
    "                    'bin_output': [bin_output], \n",
    "                    'include_nfl_features': [include_nfl_features],\n",
    "                    'f1_score': [f1_metric],\n",
    "                    'confusion_matrix': [confusion_mat], \n",
    "                    'accuracy_score': [accuracy]\n",
    "                })\n",
    "                results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>regression/classification</th>\n",
       "      <th>train_time</th>\n",
       "      <th>MSE pre-bin</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>bin_output</th>\n",
       "      <th>include_nfl_features</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>classification</td>\n",
       "      <td>15.563212</td>\n",
       "      <td>4.589559e+01</td>\n",
       "      <td>-7.698460e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.222991</td>\n",
       "      <td>[[0, 0, 2, 7, 49, 31, 1], [0, 1, 11, 16, 100, ...</td>\n",
       "      <td>0.283041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>3.167168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.222580</td>\n",
       "      <td>[[0, 10, 7, 4, 48, 17, 4], [1, 24, 10, 23, 99,...</td>\n",
       "      <td>0.265497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>1.765484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.222254</td>\n",
       "      <td>[[0, 9, 6, 8, 52, 7, 8], [1, 20, 17, 13, 103, ...</td>\n",
       "      <td>0.269591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.570791</td>\n",
       "      <td>4.643932e+01</td>\n",
       "      <td>-8.974371e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.219132</td>\n",
       "      <td>[[0, 2, 3, 8, 44, 33, 0], [1, 6, 11, 14, 100, ...</td>\n",
       "      <td>0.269006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.493404</td>\n",
       "      <td>4.769684e+01</td>\n",
       "      <td>-1.192527e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.217885</td>\n",
       "      <td>[[1, 0, 5, 10, 42, 30, 2], [1, 9, 4, 20, 97, 4...</td>\n",
       "      <td>0.270175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.876631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.217713</td>\n",
       "      <td>[[1, 7, 7, 3, 64, 7, 1], [0, 18, 14, 7, 131, 1...</td>\n",
       "      <td>0.296491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>2.198357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.217139</td>\n",
       "      <td>[[2, 9, 6, 2, 56, 14, 1], [0, 19, 16, 13, 113,...</td>\n",
       "      <td>0.276023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>1.967382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216091</td>\n",
       "      <td>[[2, 7, 8, 4, 48, 18, 3], [0, 19, 19, 19, 99, ...</td>\n",
       "      <td>0.267836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>classification</td>\n",
       "      <td>19.386551</td>\n",
       "      <td>4.423136e+01</td>\n",
       "      <td>-3.793183e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.213482</td>\n",
       "      <td>[[0, 1, 3, 8, 46, 31, 1], [0, 2, 9, 17, 95, 59...</td>\n",
       "      <td>0.276023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.963426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.213334</td>\n",
       "      <td>[[1, 8, 2, 2, 69, 6, 2], [0, 19, 11, 7, 136, 1...</td>\n",
       "      <td>0.298246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.171723</td>\n",
       "      <td>6.190857e+13</td>\n",
       "      <td>-1.452745e+12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.209398</td>\n",
       "      <td>[[1, 2, 4, 7, 46, 28, 2], [3, 2, 3, 25, 88, 61...</td>\n",
       "      <td>0.269591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>4.236483e+01</td>\n",
       "      <td>5.868126e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.205164</td>\n",
       "      <td>[[0, 2, 4, 3, 52, 29, 0], [1, 2, 2, 25, 89, 64...</td>\n",
       "      <td>0.268421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.137578</td>\n",
       "      <td>4.461528e+12</td>\n",
       "      <td>-1.046941e+11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.193943</td>\n",
       "      <td>[[0, 1, 3, 8, 43, 32, 3], [3, 2, 2, 19, 103, 5...</td>\n",
       "      <td>0.255556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.035593</td>\n",
       "      <td>4.283058e+01</td>\n",
       "      <td>-5.061226e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191236</td>\n",
       "      <td>[[0, 1, 4, 7, 45, 33, 0], [0, 3, 0, 20, 102, 5...</td>\n",
       "      <td>0.254386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.183787</td>\n",
       "      <td>[[24, 14, 8, 4, 16, 11, 13], [37, 41, 28, 11, ...</td>\n",
       "      <td>0.179532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176455</td>\n",
       "      <td>[[23, 13, 8, 5, 15, 12, 14], [37, 38, 28, 11, ...</td>\n",
       "      <td>0.171930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.035743</td>\n",
       "      <td>4.186152e+01</td>\n",
       "      <td>1.767875e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.172279</td>\n",
       "      <td>[[0, 0, 0, 0, 58, 32, 0], [0, 0, 0, 0, 125, 59...</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.035940</td>\n",
       "      <td>4.219983e+01</td>\n",
       "      <td>9.740051e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.171351</td>\n",
       "      <td>[[0, 0, 0, 0, 61, 29, 0], [0, 0, 0, 0, 125, 59...</td>\n",
       "      <td>0.264912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.033545</td>\n",
       "      <td>4.216492e+01</td>\n",
       "      <td>1.055918e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.170147</td>\n",
       "      <td>[[0, 0, 0, 0, 56, 34, 0], [0, 0, 0, 0, 113, 71...</td>\n",
       "      <td>0.258480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.033853</td>\n",
       "      <td>4.227143e+01</td>\n",
       "      <td>8.059950e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.169616</td>\n",
       "      <td>[[0, 0, 0, 0, 59, 31, 0], [0, 0, 0, 0, 123, 61...</td>\n",
       "      <td>0.261404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVR</td>\n",
       "      <td>classification</td>\n",
       "      <td>5.582083</td>\n",
       "      <td>4.559748e+01</td>\n",
       "      <td>-6.998910e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.574784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVC</td>\n",
       "      <td>classification</td>\n",
       "      <td>6.939877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.351680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.387594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVR</td>\n",
       "      <td>classification</td>\n",
       "      <td>6.527270</td>\n",
       "      <td>4.559832e+01</td>\n",
       "      <td>-7.000893e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>classification</td>\n",
       "      <td>9.718363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.533408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>[[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...</td>\n",
       "      <td>0.292982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>classification</td>\n",
       "      <td>1.024605</td>\n",
       "      <td>9.827038e+01</td>\n",
       "      <td>-1.306010e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.087351</td>\n",
       "      <td>[[0, 0, 0, 3, 3, 43, 41], [0, 0, 0, 8, 10, 89,...</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.954760</td>\n",
       "      <td>1.061887e+02</td>\n",
       "      <td>-1.491821e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 18, 72], [0, 0, 0, 0, 0, 37, ...</td>\n",
       "      <td>0.123977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model regression/classification  train_time  \\\n",
       "27   RandomForestRegressor            classification   15.563212   \n",
       "6            XGBClassifier            classification    3.167168   \n",
       "21           XGBClassifier            classification    1.765484   \n",
       "14            XGBRegressor            classification    0.570791   \n",
       "29            XGBRegressor            classification    0.493404   \n",
       "20      AdaBoostClassifier            classification    0.876631   \n",
       "4   RandomForestClassifier            classification    2.198357   \n",
       "19  RandomForestClassifier            classification    1.967382   \n",
       "12   RandomForestRegressor            classification   19.386551   \n",
       "5       AdaBoostClassifier            classification    0.963426   \n",
       "7         LinearRegression            classification    0.171723   \n",
       "9                    Ridge            classification    0.039000   \n",
       "22        LinearRegression            classification    0.137578   \n",
       "24                   Ridge            classification    0.035593   \n",
       "3               GaussianNB            classification    0.036829   \n",
       "18              GaussianNB            classification    0.034381   \n",
       "10              ElasticNet            classification    0.035743   \n",
       "8                    Lasso            classification    0.035940   \n",
       "25              ElasticNet            classification    0.033545   \n",
       "23                   Lasso            classification    0.033853   \n",
       "26                     SVR            classification    5.582083   \n",
       "0       LogisticRegression            classification    0.574784   \n",
       "17                     SVC            classification    6.939877   \n",
       "16              Perceptron            classification    0.351680   \n",
       "1               Perceptron            classification    0.387594   \n",
       "11                     SVR            classification    6.527270   \n",
       "2                      SVC            classification    9.718363   \n",
       "15      LogisticRegression            classification    0.533408   \n",
       "13       AdaBoostRegressor            classification    1.024605   \n",
       "28       AdaBoostRegressor            classification    0.954760   \n",
       "\n",
       "     MSE pre-bin      r2_score bin_output include_nfl_features  f1_score  \\\n",
       "27  4.589559e+01 -7.698460e-02      False                False  0.222991   \n",
       "6            NaN           NaN       True                 True  0.222580   \n",
       "21           NaN           NaN       True                False  0.222254   \n",
       "14  4.643932e+01 -8.974371e-02      False                 True  0.219132   \n",
       "29  4.769684e+01 -1.192527e-01      False                False  0.217885   \n",
       "20           NaN           NaN       True                False  0.217713   \n",
       "4            NaN           NaN       True                 True  0.217139   \n",
       "19           NaN           NaN       True                False  0.216091   \n",
       "12  4.423136e+01 -3.793183e-02      False                 True  0.213482   \n",
       "5            NaN           NaN       True                 True  0.213334   \n",
       "7   6.190857e+13 -1.452745e+12      False                 True  0.209398   \n",
       "9   4.236483e+01  5.868126e-03      False                 True  0.205164   \n",
       "22  4.461528e+12 -1.046941e+11      False                False  0.193943   \n",
       "24  4.283058e+01 -5.061226e-03      False                False  0.191236   \n",
       "3            NaN           NaN       True                 True  0.183787   \n",
       "18           NaN           NaN       True                False  0.176455   \n",
       "10  4.186152e+01  1.767875e-02      False                 True  0.172279   \n",
       "8   4.219983e+01  9.740051e-03      False                 True  0.171351   \n",
       "25  4.216492e+01  1.055918e-02      False                False  0.170147   \n",
       "23  4.227143e+01  8.059950e-03      False                False  0.169616   \n",
       "26  4.559748e+01 -6.998910e-02      False                False  0.132776   \n",
       "0            NaN           NaN       True                 True  0.132776   \n",
       "17           NaN           NaN       True                False  0.132776   \n",
       "16           NaN           NaN       True                False  0.132776   \n",
       "1            NaN           NaN       True                 True  0.132776   \n",
       "11  4.559832e+01 -7.000893e-02      False                 True  0.132776   \n",
       "2            NaN           NaN       True                 True  0.132776   \n",
       "15           NaN           NaN       True                False  0.132776   \n",
       "13  9.827038e+01 -1.306010e+00      False                 True  0.087351   \n",
       "28  1.061887e+02 -1.491821e+00      False                False  0.048680   \n",
       "\n",
       "                                     confusion_matrix  accuracy_score  \n",
       "27  [[0, 0, 2, 7, 49, 31, 1], [0, 1, 11, 16, 100, ...        0.283041  \n",
       "6   [[0, 10, 7, 4, 48, 17, 4], [1, 24, 10, 23, 99,...        0.265497  \n",
       "21  [[0, 9, 6, 8, 52, 7, 8], [1, 20, 17, 13, 103, ...        0.269591  \n",
       "14  [[0, 2, 3, 8, 44, 33, 0], [1, 6, 11, 14, 100, ...        0.269006  \n",
       "29  [[1, 0, 5, 10, 42, 30, 2], [1, 9, 4, 20, 97, 4...        0.270175  \n",
       "20  [[1, 7, 7, 3, 64, 7, 1], [0, 18, 14, 7, 131, 1...        0.296491  \n",
       "4   [[2, 9, 6, 2, 56, 14, 1], [0, 19, 16, 13, 113,...        0.276023  \n",
       "19  [[2, 7, 8, 4, 48, 18, 3], [0, 19, 19, 19, 99, ...        0.267836  \n",
       "12  [[0, 1, 3, 8, 46, 31, 1], [0, 2, 9, 17, 95, 59...        0.276023  \n",
       "5   [[1, 8, 2, 2, 69, 6, 2], [0, 19, 11, 7, 136, 1...        0.298246  \n",
       "7   [[1, 2, 4, 7, 46, 28, 2], [3, 2, 3, 25, 88, 61...        0.269591  \n",
       "9   [[0, 2, 4, 3, 52, 29, 0], [1, 2, 2, 25, 89, 64...        0.268421  \n",
       "22  [[0, 1, 3, 8, 43, 32, 3], [3, 2, 2, 19, 103, 5...        0.255556  \n",
       "24  [[0, 1, 4, 7, 45, 33, 0], [0, 3, 0, 20, 102, 5...        0.254386  \n",
       "3   [[24, 14, 8, 4, 16, 11, 13], [37, 41, 28, 11, ...        0.179532  \n",
       "18  [[23, 13, 8, 5, 15, 12, 14], [37, 38, 28, 11, ...        0.171930  \n",
       "10  [[0, 0, 0, 0, 58, 32, 0], [0, 0, 0, 0, 125, 59...        0.263158  \n",
       "8   [[0, 0, 0, 0, 61, 29, 0], [0, 0, 0, 0, 125, 59...        0.264912  \n",
       "25  [[0, 0, 0, 0, 56, 34, 0], [0, 0, 0, 0, 113, 71...        0.258480  \n",
       "23  [[0, 0, 0, 0, 59, 31, 0], [0, 0, 0, 0, 123, 61...        0.261404  \n",
       "26  [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "0   [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "17  [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "16  [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "1   [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "11  [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "2   [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "15  [[0, 0, 0, 0, 90, 0, 0], [0, 0, 0, 0, 184, 0, ...        0.292982  \n",
       "13  [[0, 0, 0, 3, 3, 43, 41], [0, 0, 0, 8, 10, 89,...        0.157895  \n",
       "28  [[0, 0, 0, 0, 0, 18, 72], [0, 0, 0, 0, 0, 37, ...        0.123977  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = 'f1_score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depreciated - run through on one dataset/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y matrices\n",
    "y = plays_df_clean[\"TARGET\"]\n",
    "X = plays_df_clean.drop([\"TARGET\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :  (5127, 348)\n",
      "y_train shape :  (5127,)\n",
      "X_test shape  :  (1710, 348)\n",
      "y_test shape  :  (1710,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=24)\n",
    "\n",
    "print('X_train shape : ', X_train.shape)\n",
    "print('y_train shape : ', y_train.shape)\n",
    "\n",
    "print('X_test shape  : ', X_test.shape)\n",
    "print('y_test shape  : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 15.882904052734375\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X = X_train, y = y_train)\n",
    "print(\"training time: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestRegressor'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: \n",
      "45.21479333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \\n\" + str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [float('-inf'), -2, 0, 1, 2.5, 5, 10, float('inf')]\n",
    "y_pred_binned = pd.cut(y_pred, bins = bins, labels = range(len(bins) - 1))\n",
    "y_test_binned = pd.cut(y_test, bins = bins, labels = range(len(bins) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[  0   0   2   7  48  32   1]\n",
      " [  0   2  12  16 103  47   4]\n",
      " [  0   3  12  19  92  50   9]\n",
      " [  0   2   4  18 136  58   7]\n",
      " [  0   0   0  29 292 164  16]\n",
      " [  0   0   0  10 165 139  11]\n",
      " [  0   0   0   8  95  87  10]]\n",
      "F1 score: 0.216\n",
      "Accuracy score: 0.277\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix: \\n\" + str(confusion_matrix(y_test_binned, y_pred_binned)))\n",
    "print(\"F1 score: \" + str(round(f1_score(y_test_binned, y_pred_binned, average='weighted'), 3)))\n",
    "print(\"Accuracy score: \" + str(round(accuracy_score(y_test_binned, y_pred_binned), 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
